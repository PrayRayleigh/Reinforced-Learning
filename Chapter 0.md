##<center>:clap:Chapter-0  Introducton
##:point_left:Beginning
&emsp;&emsp;What's Needed before you work
- [x] Enough Time
- [x] Peaceful autitude
- [x] Steady planning
##:book: OverView
- [ ] Chapter 1 Basic-Concepts MDP
- [ ] Chapter 2 Bellman Formula & State value 
- [ ] Chapter 3 Bellman-Best Formula 
- [ ] Chapter 4 Value & Policy Iteration 
- [ ] Chapter 5 No Model RL->Monte Carlo Learning
- [ ] Chapter 6 Stochastic Approximation
- [ ] Chapter 7 Classical RL algroithms
- [ ] Chapter 8 ValueFunction Approximation Algroithms
- [ ] Chapter 9 From Value-Based to Policy-Based 
- [ ] Chapter 10 Actor-Critic 
